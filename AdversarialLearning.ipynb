{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "from urllib import request\n",
    "import scipy.stats as st\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data: Use gdown to download data files from Google Drive\n",
    "import gdown\n",
    "ids = [\n",
    "    '1XHEWIiTv9Czjn9RJ6IHu_fWXfrteks5l',\n",
    "    '1gwa_5bTO3dchDlC3WZ3nt_0VvwBkvFfi',\n",
    "    '1DCUuuy20k-dNbUnCyi0HI9O7qy8hOpE5'\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    'train.csv',\n",
    "    'test.csv',\n",
    "    'img.zip'\n",
    "]\n",
    "\n",
    "for i, o in zip(ids, outputs):\n",
    "    gdown.download(id=i, output=o, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded image file\n",
    "!unzip -qq \"/content/img.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load image metadata (Image_ID, true label, and target label) from a CSV file\n",
    "def load_ground_truth(fname):\n",
    "    image_id_list = []\n",
    "    label_ori_list = []\n",
    "    label_tar_list = []\n",
    "\n",
    "    df = pd.read_csv(fname)\n",
    "    for _, row in df.iterrows():\n",
    "        image_id_list.append( row['ImageId'] )\n",
    "        label_ori_list.append( int(row['TrueLabel']) - 1 )\n",
    "        label_tar_list.append( int(row['TargetClass']) - 1 )\n",
    "    gt = pickle.load(request.urlopen('https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl'))\n",
    "    return image_id_list,label_ori_list,label_tar_list, gt\n",
    "\n",
    "## simple Module to normalize an image using given mean and standard deviation\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.Tensor(mean)\n",
    "        self.std = torch.Tensor(std)\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eff970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# Set up normalization and transformation for images\n",
    "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "trn = transforms.Compose([transforms.ToTensor(),])\n",
    "# Load image metadata\n",
    "ids, origins, targets, gt = load_ground_truth('train.csv')\n",
    "\n",
    "# Set parameters\n",
    "batch_size = 20\n",
    "max_iterations = 100\n",
    "input_path = 'images/'\n",
    "epochs = int(np.ceil(len(ids) / batch_size))\n",
    "\n",
    "img_size = 299\n",
    "lr = 2 / 255 #step size\n",
    "epsilon = 16 # L_inf norm bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\").eval()\n",
    "vgg = models.vgg16_bn(weights=\"IMAGENET1K_V1\").eval()\n",
    "\n",
    "# Freeze model parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Move models to the GPU\n",
    "resnet.to(device)\n",
    "vgg.to(device)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc85b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function for input diversity (DI-FGSM)\n",
    "def input_diversity(image, prob=0.5):\n",
    "    if torch.rand(1).item() > prob:\n",
    "        return image  # Skip diversity with probability (1 - prob)\n",
    "\n",
    "    batch_size, channels, height, width = image.shape\n",
    "    # Random resizing\n",
    "    rnd = np.random.randint(299, 330)  # Random size in [299, 330)\n",
    "    resized_image = F.interpolate(image, size=(rnd, rnd), mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Random padding to 330x330\n",
    "    pad_top = np.random.randint(0, 330 - rnd)\n",
    "    pad_bottom = 330 - rnd - pad_top\n",
    "    pad_left = np.random.randint(0, 330 - rnd)\n",
    "    pad_right = 330 - rnd - pad_left\n",
    "    padded_image = F.pad(resized_image, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0)\n",
    "\n",
    "    # Crop back to 299x299\n",
    "    cropped_image = padded_image[:, :, :299, :299]\n",
    "    return cropped_image\n",
    "\n",
    "# Pre-compute Gaussian kernel for TI-FGSM\n",
    "def gaussian_kernel(size=5, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Create a Gaussian kernel for convolution.\n",
    "    \"\"\"\n",
    "    ax = np.arange(-size // 2 + 1, size // 2 + 1)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return torch.tensor(kernel, dtype=torch.float32)\n",
    "\n",
    "# Apply Gaussian kernel to gradients\n",
    "def apply_ti_gradient(grad, kernel):\n",
    "    \"\"\"\n",
    "    Apply translation-invariant Gaussian blur to the gradient.\n",
    "    \"\"\"\n",
    "    channels, _, k_h, k_w = kernel.shape\n",
    "    return F.conv2d(grad, kernel, padding=(k_h // 2, k_w // 2), groups=channels)\n",
    "\n",
    "# Define Gaussian kernel\n",
    "kernel_size = 15\n",
    "sigma = 1.0\n",
    "kernel = gaussian_kernel(kernel_size, sigma).unsqueeze(0).unsqueeze(0).repeat(3, 1, 1, 1).to(device)  # 3 channels (RGB)\n",
    "\n",
    "# Momentum factor for MI-FGSM\n",
    "momentum = 1.0\n",
    "\n",
    "# Initialize lists to store predictions, labels, and original indices\n",
    "preds_ls = []\n",
    "labels_ls = []\n",
    "origin_ls = []\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Loop through epochs\n",
    "for k in tqdm(range(epochs), total=epochs):\n",
    "    batch_size_cur = min(batch_size, len(ids) - k * batch_size)  # Determine the current batch size\n",
    "    # Initialize tensors for the original images and the perturbations\n",
    "    X_ori = torch.zeros(batch_size_cur, 3, 299, 299).to(device)  # Match the original image size\n",
    "    delta = torch.zeros_like(X_ori, requires_grad=True).to(device)\n",
    "    # Momentum vector\n",
    "    g = torch.zeros_like(delta).to(device)\n",
    "\n",
    "    # Load and transform images\n",
    "    for i in range(batch_size_cur):\n",
    "        X_ori[i] = trn(Image.open(input_path + ids[k * batch_size + i] + '.png'))\n",
    "    # Extract the original indices for the current batch\n",
    "    ori_idx = origins[k * batch_size:k * batch_size + batch_size_cur]\n",
    "\n",
    "    # Determine the least-likely class for each image\n",
    "    with torch.no_grad():\n",
    "        logits = resnet(norm(X_ori))\n",
    "        least_likely_class = torch.argmin(logits, dim=1)\n",
    "\n",
    "    labels = least_likely_class.to(device)\n",
    "\n",
    "    # Adversarial attack loop\n",
    "    for t in range(max_iterations):\n",
    "        # Apply input diversity\n",
    "        diversified_image = input_diversity(X_ori + delta, prob=0.5)\n",
    "        # Compute the logits (predictions) of the ResNet model for the diversified input\n",
    "        logits = resnet(norm(diversified_image))\n",
    "        # Calculate the cross-entropy loss between the logits and the least-likely class labels\n",
    "        loss = nn.CrossEntropyLoss(reduction='sum')(logits, labels)\n",
    "        # Perform backpropagation to compute the gradients of the loss with respect to delta\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply TI-FGSM (blur gradients)\n",
    "        grad = apply_ti_gradient(delta.grad, kernel)\n",
    "\n",
    "        # Add momentum (MI-FGSM)\n",
    "        grad = grad / torch.norm(grad, p=2)  # Normalize gradient\n",
    "        g = momentum * g + grad  # Accumulate gradients with momentum of 1.0\n",
    "\n",
    "        # Update delta using the momentum-integrated gradient\n",
    "        delta.data = delta.data - lr * torch.sign(g)\n",
    "\n",
    "        # Clamp the values of delta (perturbation) to ensure they stay within the specified L_inf norm bound\n",
    "        delta.data = delta.data.clamp(-epsilon / 255, epsilon / 255)\n",
    "\n",
    "        # Reset the gradients of delta to zero to prevent accumulation in the next iteration\n",
    "        delta.grad.zero_()\n",
    "\n",
    "    # Normalize perturbed images\n",
    "    X_pur = norm(X_ori + delta)\n",
    "    # Get predictions from the VGG model for the perturbed images\n",
    "    preds = torch.argmax(vgg(X_pur), dim=1)\n",
    "\n",
    "    # Store Results\n",
    "    preds_ls.append(preds.cpu().numpy())\n",
    "    labels_ls.append(labels.cpu().numpy())\n",
    "    origin_ls.append(ori_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'origin': [a for b in origin_ls for a in b],\n",
    "    'pred': [a for b in preds_ls for a in b],\n",
    "    'label': [a for b in labels_ls for a in b]\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show accuracy\n",
    "accuracy_score(df['label'], df['pred'])\n",
    "accuracy_score(df['origin'], df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ac85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dad670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of some adversarial examples\n",
    "def viz(img_A, img_B, origins, labels, gt, preds):\n",
    "    for img_a, img_b, origin, label, pred in zip(img_A, img_B, origins, labels, preds):\n",
    "        img_a = img_a.permute(1, 2, 0)\n",
    "        img_b = img_b.permute(1, 2, 0)\n",
    "\n",
    "        fig, (axA, axB) = plt.subplots(1, 2, figsize=(10,3))\n",
    "        axA.imshow(img_a)\n",
    "        axA.set_title(\"True label: \" + gt[origin])\n",
    "        axB.imshow(img_b)\n",
    "        axB.set_title(\"Target: \" + gt[label])\n",
    "\n",
    "        result = 'Failed' if pred != label else 'Success'\n",
    "        caption = f'Pred: {gt[pred]} -> {result}'\n",
    "        fig.text(0.5, -0.05, caption, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "viz(X_ori.cpu().detach(), X_pur.cpu().detach(), ori_idx, labels.cpu().numpy(), gt, preds.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
